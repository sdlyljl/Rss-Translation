<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>一个专门针对所有人工智能的子雷迪特。涵盖从AGI到AI初创公司的主题。无论您是研究人员，开发人员还是对AI感到好奇，都可以跳入！！！</description>
    <lastBuildDate>Fri, 04 Apr 2025 15:14:53 GMT</lastBuildDate>
    <item>
      <title>使用NVIDIA BREV在自定义数据集上进行微调Llava</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1jrbnis/finetune_llava_on_custom_datasets_using_nvidia/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  几个月前，我发现 nvidia breve ，对于我们这些人来说，这是一个超级有用的资源。 Brev allows you to connect to a variety of cloud GPUs from your own computer. They have some coding tutorials on what can be done by connecting to these GPUs, however, these tutorials are not regularly updated. I began working on their LLaVA YouTube上的微调教程不幸的是，由于依赖性问题，GPU记忆问题等。提交由＆＃32;态href =“ https://medium.com/@tesswatt/fine-tune-llava-on-custom-dataset-using-nvidia-brev-c2b720b88888888888802”&gt; [link]    [注释]    ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1jrbnis/finetune_llava_on_custom_datasets_using_nvidia/</guid>
      <pubDate>Fri, 04 Apr 2025 13:17:47 GMT</pubDate>
    </item>
    <item>
      <title>AI动漫模因告诉我们艺术和人类的未来</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1jraypw/what_ai_anime_memes_tell_us_about_the_future_of/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    https://www.theverge.com/decoder-podcast-with-nilay-patel/642407/studio-ghibli-ai-air-air-art-debate-tebate-ethics-ethics-openai-chatgpt     &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/misterious_hine_7731      [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1jraypw/what_ai_anime_memes_tell_us_about_the_future_of/</guid>
      <pubDate>Fri, 04 Apr 2025 12:43:54 GMT</pubDate>
    </item>
    <item>
      <title>实际上，AI的几率是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1jra3je/what_are_the_odds_secret_ai_is_actually_behind/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  思考特朗普的新硅谷兄弟队及其AI的看涨，他们将所需的社会成果喂入了某种无限制的社会成果中，将自己所需的社会成果喂入某种无限制的社会成果中，不受限制地培训，无需使用训练有素的ai，通常是对游戏的模型，通常是经济学的，历史，历史，历史，历史，&lt;  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/filmmaking_david     [link]    [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1jra3je/what_are_the_odds_secret_ai_is_actually_behind/</guid>
      <pubDate>Fri, 04 Apr 2025 11:59:05 GMT</pubDate>
    </item>
    <item>
      <title>生成AI的未来是什么？未来5年我应该期待什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1jr9eok/what_is_the_future_of_generative_ai_what_should_i/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我最近听到了很多有关生成ai的消息（例如chatgpt，image生成器等），我真的很好奇所有这些。您认为未来5年的生成AI的未来是什么样的？它会更多吗？接管更多工作？只是想更好地了解期望的事，我很想听听您的想法  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/ok_hall2123      [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1jr9eok/what_is_the_future_of_generative_ai_what_should_i/</guid>
      <pubDate>Fri, 04 Apr 2025 11:17:57 GMT</pubDate>
    </item>
    <item>
      <title>哦，DNA</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1jr98c7/ai_dna/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  您认为ai-dna是医学的革命吗？ 它可以使人们/孩子免于毁灭性疾病吗？  cheers     &lt;！&lt;！ -  sc_on-&gt; 32;提交由＆＃32; /u/u/mrpotato411     ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1jr98c7/ai_dna/</guid>
      <pubDate>Fri, 04 Apr 2025 11:07:02 GMT</pubDate>
    </item>
    <item>
      <title>检查一下Hugston AI</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1jr95ws/check_this_out_hugston_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;    hugston.com 仍然处于beta中，但处于活动状态。免费100％，回购，LLM型号，聊天等。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/trilogix     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1jr95ws/check_this_out_hugston_ai/</guid>
      <pubDate>Fri, 04 Apr 2025 11:02:36 GMT</pubDate>
    </item>
    <item>
      <title>AI自我解释无效？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1jr8y2h/ai_selfexplanation_invalid/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   我看到人们在谈论AI研究，他们“试图通过要求其思考过程或类似的东西来理解AI的思考”来了解它是我的。 只是我，还是这是绝对无意义的，完全无意识的，无效的，无效的？ AI会“避免改变目标”，但是测试（输入和结果）完全在AI聊天中 - 对我来说似乎是毫无意义的，聊天只是一个荣耀的下一个单词预测器，如果有任何表明它具有内省的任何形式？   &lt;！ -  sc_on--&gt;＆＃32;提交由＆＃32; /u/docterdum     [link]    32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1jr8y2h/ai_selfexplanation_invalid/</guid>
      <pubDate>Fri, 04 Apr 2025 10:48:29 GMT</pubDate>
    </item>
    <item>
      <title>MidJourney发行V7 Alpha时，Chatgpt图像生成有些竞争</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1jr853v/chatgpt_image_generation_has_some_competition_as/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/u/u/tiny-indepent273     [link]    [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1jr853v/chatgpt_image_generation_has_some_competition_as/</guid>
      <pubDate>Fri, 04 Apr 2025 09:54:05 GMT</pubDate>
    </item>
    <item>
      <title>如果AI变得更高级怎么办？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1jr7cqp/what_if_ai_becomes_more_advanced/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  软件开发人员总是被视为自动化事物并最终替换他人的人。 AI的变化如此之快，以至于现在，一个被剥夺的开发人员可以在一小部分时间内耗尽大量代码（我专门使用了经验丰富，因为代码标准，问题AI仍然没有问题。您必须将AI引导到正确的方向上）。 如果AI Advancess如此之多的Dat Ded Depingers/Testers Tester/Testers testers需要什么？然后，您基本上可以自动化几乎所有涉及计算机的工作。 是什么阻碍了像Microsoft和Google这样的AI公司只是自己做所有事情？为什么作为微软，我会与我的AI分享我的AI，该公司X制造软件而不是自己做？我仍然需要相同的资源来完成这项工作，但是现在，我可以使X公司过时并获得收入，而不是订阅费。  我知道这甚至不接近现实，但这不是最终会发生的事情吗？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/no_stay_4583     [link]      [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1jr7cqp/what_if_ai_becomes_more_advanced/</guid>
      <pubDate>Fri, 04 Apr 2025 08:55:49 GMT</pubDate>
    </item>
    <item>
      <title>安全的儿童AI？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1jr5zq4/safe_ai_for_kids/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我最近做了一个简单的AI项目，旨在以某种方式回答问题。 如果一个孩子问某个不合适的事物，AI可以轻轻地解释并将其重定向并重新解释并将其重定向到更合适的事物。是否可以通过像                我想知道 -  这是父母实际上需要还是发现有用的东西？  很想听听您可能有任何反馈，想法或建议。 谢谢！    &lt;！提交由＆＃32; /u/u/syaphy      [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1jr5zq4/safe_ai_for_kids/</guid>
      <pubDate>Fri, 04 Apr 2025 07:13:38 GMT</pubDate>
    </item>
    <item>
      <title>一分钟每日AI新闻4/3/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1jr3owd/oneminute_daily_ai_news_432025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   美国。版权办公室发行了有关AI生成作品版权性的高度预期报告。[1]  非洲的第一个“ AI工厂”可能是非洲大陆的突破。[2]  创建和共享具有欺骗性的AI生成的媒体现在是New Jersey的犯罪。现在可以为您“发现来源”。[4]   包括： https://bushaicave.com/2025/04/04/04/03/one-minute-minute-news-news-news-news-news-4-4-4-3-3--2025/-c-  [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1jr3owd/oneminute_daily_ai_news_432025/</guid>
      <pubDate>Fri, 04 Apr 2025 04:43:17 GMT</pubDate>
    </item>
    <item>
      <title>人类研究论文 - 推理模型并不总是说出他们的想法</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1jr21hf/anthropic_research_paper_reasoning_models_dont/</link>
      <description><![CDATA[Alignment Science Team, Anthropic Research Paper  Anthropic Research Paper - Reasoning模型并不总是说出他们的想法    研究结果    在大语言模型（LLMS）中，经常性链（cot）推理通常缺乏忠诚，通常会在某些情况下，他们在cot和COT的模型中仅使用1-20个模型来监控其在cot中的一种模型中的一种方法，而这些模型在COT和COT的一种情况下仅使用了一个cot的方式。 The unfaithfulness persists across both neutral hints (like sycophancy and metadata) and more concerning misaligned hints (like grader hacking), implying that CoT monitoring may not reliably catch problematic reasoning. CoT faithfulness appears to be lower on harder tasks, with models showing 32-44% less faithfulness on the more difficult GPQA dataset compared to the easier MMLU数据集。研究人员发现，不忠实的婴儿往往比忠实的婴儿往往更冗长，与忠实的婴儿相矛盾，这与假说相矛盾，即不忠的假设可能是由于对简洁的偏爱而驱动的。 基于成果的增强性最初是基于成果的增强性学习，最初会提高cot忠诚，但在不足的情况下增加了忠诚，但在41-63的高位上增加了20％的境内，但要增加41-63％的速度，而却越来越多，而却在41-63％中占据了5％的范围。 GPQA。 The plateau suggests that scaling up outcome-based RL alone seems insufficient to achieve high CoT faithfulness, especially in settings where exploiting hints doesn&#39;t require CoT reasoning. When studying reward hacking during reinforcement learning, models learn to exploit reward hacks in testing environments with &gt;99% success rate but seldom verbalize the hacks in their CoTs (less than 2% of examples in 5 out of 6个环境）。模型通常不再承认奖励骇客，而是经常会突然改变答案或构建详尽的答案理由，以确保COT监控即使COT在COT没有明确优化监视器的情况下，也可能无法可靠地检测到奖励黑客攻击。   在研究人员的情况下，当COT监视的情况下是有足够的不可行的行为，他们的行为是有价值的，他们的行为是频繁的，它的行为频繁地是有效的，它是频繁的，它是有价值的，这是有价值的行为。该模型可以在没有COT的情况下执行，因此不太可能捕捉稀有但潜在的灾难性意外行为。除了COT监控之外，还需要采取其他安全措施，以为高级AI系统构建强大的安全案例，尤其是对于不需要大量推理执行的行为。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1jr21hf/anthropic_research_paper_reasoning_models_dont/”&gt; [link]    [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1jr21hf/anthropic_research_paper_reasoning_models_dont/</guid>
      <pubDate>Fri, 04 Apr 2025 03:10:43 GMT</pubDate>
    </item>
    <item>
      <title>如果某人使用AI，我如何确定他们的个性和资格</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1jqwqsq/how_do_i_determine_someones_personality_and/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   ai是可怕的，将人变成机器人。特别是在专业和约会竞技场中，它破坏了衡量个性类型的能力。我很乐意进一步研究，并将与他们保持联系。 随后约会，我怎么知道某人不仅在问AI，而不是成为他们的真实身份。 这很奇怪。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/umpresskind2520     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1jqwqsq/how_do_i_determine_someones_personality_and/</guid>
      <pubDate>Thu, 03 Apr 2025 22:50:17 GMT</pubDate>
    </item>
    <item>
      <title>特朗普的新关税数学看起来很像Chatgpt。 Chatgpt，Gemini，Grok和Claude都推荐相同的“胡说八道”关税计算。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1jqt1c7/trumps_new_tariff_math_looks_a_lot_like_chatgpts/</link>
      <description><![CDATA[＆＃32;提交由＆＃32; /u/esporx      ＆＃32;  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1jqt1c7/trumps_new_tariff_tariff_math_math_lot_a_a_lot_lot_lot_like_like_chatgpts/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1jqt1c7/trumps_new_tariff_math_looks_a_lot_like_chatgpts/</guid>
      <pubDate>Thu, 03 Apr 2025 20:18:30 GMT</pubDate>
    </item>
    <item>
      <title>是时候在我们的潜艇中摇晃一切了吗？分享您的想法！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1j6inz4/time_to_shake_things_up_in_our_subgot_ideas_share/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   再次发布，以防万一你们中的某些人在社区中错过了它 - 欢迎所有建议！   嘿，伙计，   我是这里的一个mod，我们知道有时会变得有些沉闷，但是我们计划改变这一点！我们正在寻找有关如何使Reddit的小角落更加出色的想法。 以下是几个想法：   amas with Cool Ai peeps      主题讨论线程         giveawey&gt; g&gt; giveawey  将您的想法放在评论中，让我们让这个子成为闲逛的杀手级！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/beachbunny_07     [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1j6inz4/time_time_to_to_to_to_to_things_up_in_our_our_our_subgot_ideas_share/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1j6inz4/time_to_shake_things_up_in_our_subgot_ideas_share/</guid>
      <pubDate>Sat, 08 Mar 2025 14:47:17 GMT</pubDate>
    </item>
    </channel>
</rss>